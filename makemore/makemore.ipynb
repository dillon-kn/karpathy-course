{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = open('names.txt', 'r').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementing a bigram (2-gram) model: only one character predicts the next\n",
    "import torch\n",
    "\n",
    "N = torch.zeros((27, 27), dtype=torch.int32) # 26 letters + start and end token\n",
    "\n",
    "# Make a mapping from characters to indices\n",
    "chars = sorted(list(set(''.join(names)))) # concatenate all names, find unique characters, then sort alphabetically\n",
    "stoi = {s:i+1 for i, s in enumerate(chars)} # map each character to an index, letting 0 be for start and end tokens\n",
    "# explicitly add start and end token\n",
    "stoi['.'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of times each character appears in a 2D array\n",
    "for name in names: # iterate over each name\n",
    "    chs = ['.'] + list(name) + ['.'] # add start and end tokens\n",
    "    \n",
    "    # iterate over each pair of characters\n",
    "    for ch1, ch2 in zip(chs, chs[1:]): # ex. <S>emma<E> -> (<S>, e), (e, m), (m, m), (m, a), (a, <E>)\n",
    "        N[stoi[ch1], stoi[ch2]] += 1 # add bigram to the count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(N)\n",
    "# Make an index to s mapping\n",
    "itos = {i:s for s, i in stoi.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cexze\n",
      "momasurailezitynn\n",
      "konimittain\n",
      "llayn\n",
      "ka\n",
      "da\n",
      "staiyaubrtthrigotai\n",
      "moliellavo\n",
      "ke\n",
      "teda\n",
      "ka\n",
      "emimmsade\n",
      "enkaviyny\n",
      "ftlspihinivenvorhlasu\n",
      "dsor\n",
      "br\n",
      "jol\n",
      "pen\n",
      "aisan\n",
      "ja\n",
      "feniee\n",
      "zem\n",
      "deru\n",
      "firit\n",
      "gaikajahahbevare\n",
      "kiysthelenaririenah\n",
      "keen\n",
      "x\n",
      "al\n",
      "kal\n",
      "thavazeeromysos\n",
      "laitenimieegariseriyen\n",
      "k\n",
      "illeleldole\n",
      "meenisammigama\n",
      "mmin\n",
      "asharin\n",
      "alcalar\n",
      "jayn\n",
      "asaz\n",
      "selanely\n",
      "chay\n",
      "rana\n",
      "ai\n",
      "yviamisashougen\n",
      "l\n",
      "beyncaro\n",
      "allan\n",
      "annutetoradrilia\n",
      "rddeman\n"
     ]
    }
   ],
   "source": [
    "# Make our bigram name language model\n",
    "\n",
    "# Make our random seed generator\n",
    "g = torch.Generator().manual_seed(2147483647)\n",
    "\n",
    "for i in range(50):\n",
    "    # Generate a name\n",
    "    name = [] # keep track of the name we're generating\n",
    "    index = 0 # start with start token, ie index token 0\n",
    "    while True:\n",
    "        # Normalize the current column (ie the probabilities of the next character)\n",
    "        p = N[index].float()\n",
    "        p /= p.sum()\n",
    "\n",
    "        # sample from the multinomial distribution once, and grab the number (this is our next index character)\n",
    "        index = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item() \n",
    "\n",
    "        # If token is end token, break\n",
    "        if index == 0:\n",
    "            break\n",
    "\n",
    "        # Else, add the character to the name and update the index\n",
    "        else:\n",
    "            name.append(itos[index])\n",
    "\n",
    "    print(''.join(name)) # print the generated name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
